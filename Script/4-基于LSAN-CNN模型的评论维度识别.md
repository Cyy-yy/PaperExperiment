# 4. 基于LSAN-CNN模型的评论维度识别

在ASAP数据集中，本文从18个细粒度评价维度中抽取出5个粗粒度评价维度，分别是价格（Price）、位置（Location）、服务（Service）、环境（Ambience）和菜品（Food）。本文将在这5个粗粒度评价维度识别任务的基础之上，将所涉及粗粒度评价维度的语义信息融合到评论文本中完成情感极性分类，因此评价维度识别任务是整个方面级情感分析任务的第一步。单个评论文本所提及的评价维度可能有一个或者多个，因此该任务本质上属于多标签文本分类任务，而当前主流的解决方案都是基于深度学习，因此本文也选取了多标签文本分类领域效果相对较好的LSAN模型作为基础模型进行改进，完成对评论文本评价维度的识别。

本章将在得到预训练词向量的基础上，进一步对评论文本中所提及的评价维度进行识别。内容方面，本章将先对LSAN模型作更加详细的介绍，并分析现有模型存在的缺陷，进而提出改进的方法，构建LSAN-CNN模型，旨在更加全面地提取评论文本的语法特征，提高评价维度识别的效果。最后通过在ASAP数据集上进行实验，比较模型改进前后对评价维度的识别效果，验证本文所提出的模型改进的有效性。

## 4.1 LSAN模型分析

为单个文本分配一个或多个标签的任务称为多标签文本分类，对该领域的研究经历了从传统机器学习方法到深度学习方法的发展。在多标签文本分类领域中，标签的数量一般不少于三个，部分场景下标签数量可达几十甚至上百个，要准确实现标签的识别存在一定的难度。在Attention机制引入该领域研究后，Xiao等在2019年提出了LSAN（Lable Specific Attention Network）模型，旨在通过捕捉标签与评论文本的关联性提高分类效果。模型整体的框架如图。

<img src="E:\研究生\毕业论文\Pictures\LSAN.jpg" alt="LSAN" style="zoom:50%;" />

### 4.1.1 LSAN模型框架

LSAN模型分为两个部分，第一部分主要从评论文本以及标签集合中挖掘相关的语义特征，第二部分对第一部分得到的特征进行自适应融合。模型输入方面，LSAN模型的输入也由两部分构成，首先是文本的词向量矩阵，其次是标签词向量矩阵。在LSAN模型中，标签被认为与文本中的单词一样具有自身的语义信息，因此也应当为每个标签赋予一个词向量。记第$i$条文本的词向量矩阵为$x_i$，其中第$j$个词的词向量为$w_j^{(i)}$，则$x^{(i)}=\{w^{(i)}_1,w^{(i)}_2,\cdots,w^{(i)}_n\}$，维度为$(k,n)$，其中$k$为词向量维度。记标签词向量为$C=\{c_1,c_2,...,c_l\}$，即共有$l$个标签，词向量维度与文本词向量维度保持一致，因此$C$的维度为$(k,l)$。

在特征提取层，LSAN模型采用了双向LSTM（Bi-LSTM）网络提取语义特征，得到隐藏层特征向量。记从左至右第$p$个时间步的隐藏层向量为$\overrightarrow{h_p}$，从右至左第$p$个时间步的隐藏层向量为$\overleftarrow{h_p}$，则有
$$
H^{(i)}=concat(\overrightarrow{H^{(i)}},\overleftarrow{H^{(i)}}) \\
\overrightarrow{H^{(i)}}=(\overrightarrow{h_1^{(i)}},\overrightarrow{h_2^{(i)}},\cdots,\overrightarrow{h_n^{(i)}}) \\
\overleftarrow{H^{(i)}}=(\overleftarrow{h_1^{(i)}},\overleftarrow{h_2^{(i)}},\cdots,\overleftarrow{h_n^{(i)}})
$$
其中，$H^{(i)}$表示第$i$条评论文本对应的隐藏层特征向量构成的矩阵，维度为$(2k,n)$。

为了更加充分地捕捉单条输入文本中单词之间的关联信息，对经过Bi-LSTM网络提取的隐藏层矩阵$H_i$作自注意力（Self-Attention）操作。首先需要计算注意力得分，其中，$W_1$和$W_2$分别是维度$(d_a,2k)$和$(l,d_a)$的参数，$d_a$为模型训练过程中的超参数，可以自行设定。$A_s^{(i)}$为第$i$条文本所对应的注意力得分矩阵，维度为$(l,n)$。将该得分矩阵$A^{(i)}_s$与隐藏层矩阵$H^{(i)}$相乘，得到基于Self-Attention机制加权的特征矩阵$M^{(i)}_s$，维度为$(l,2k)$。
$$
A^{(i)}_s=softmax(W_2tanh(W_1H^{(i)})) \\
M^{(i)}_s=A^{(i)}_s[H^{(i)}]^T
$$
除了对特征矩阵作Self-Attention操作外，更为重要的是捕捉到标签与文本之间的语义关联信息，这也是模型名称中“Label Specific”的由来。在LSAN模型中，通过计算标签词向量与Bi-LSTM隐藏层向量之间的相关性作为权重，对Bi-LSTM提取的特征向量进行加权，该步骤在模型中称为Label-Attention，最终得到基于Label-Attention机制加权的特征矩阵$M^{(i)}_l$，维度为$(l,2k)$。
$$
\overrightarrow{A^{(i)}_l}=C^T\overrightarrow{H^{(i)}} \qquad
\overleftarrow{A^{(i)}_l}=C^T\overleftarrow{H^{(i)}} \\
\overrightarrow{M^{(i)}_l}=\overrightarrow{A^{(i)}_l}[\overrightarrow{H^{(i)}}]^T \qquad
\overleftarrow{M^{(i)}_l}=\overleftarrow{A^{(i)}_l}[\overleftarrow{H^{(i)}}]^T \\
M^{(i)}_l=concat(\overrightarrow{M^{(i)}_l},\overleftarrow{M^{(i)}_l})
$$
此处，两个加权特征矩阵的维度是一致的。在第二部分，LSAN模型对特征矩阵$M^{(i)}_s$和$M^{(i)}_l$进行融合，采用的是自适应融合（Adaptive Fusion）策略。自适应融合本质上也是加权融合，不同的是权重$\alpha$和$\beta$作为可变参数，可以随着模型训练迭代更新。此外，$\alpha$和$\beta$也反映了基于Self-Attention和Label-Attention得到的特征矩阵的重要性，理论上两个权重之和应为1，模型也作了相应的限制，其中$W_3$和$W_4$是维度为$(2k,1)$的参数向量。
$$
\alpha^{(i)}=sigmoid(M^{(i)}_sW_3) \qquad
\beta^{(i)}=sigmoid(M^{(i)}_lW_4) \\
\alpha^{(i)}+\beta^{(i)}=1 \\
M^{(i)}=\alpha^{(i)}M^{(i)}_s+\beta^{(i)}M^{(i)}_l
$$
融合的特征矩阵经过两个全连接层后，输入到分类器中。对于多标签文本分类任务，单条输入文本情况下最后输出的是维度与标签数量相同的向量，向量的每一个元素代表文本属于对应位置标签的概率，本质上是多个二分类器的组合，因此在分类器层只需要将$sigmoid$函数应用到经过全连接层降维后的特征向量的每一个元素上即可。其中，$W_5$是维度为$(b,2k)$的参数，$b$为模型的超参数，而$W_6$是$b$维的向量，最终得到的预测值$\hat{y}_i$是一个$l$维向量。
$$
\hat{y}_i=sigmoid(W_6f(W_5[M^{(i)}]^T))
$$
### 4.1.2 LSAN模型损失函数

在二分类任务中，损失函数为交叉熵损失函数，而多标签文本分类又可以看作多个二分类任务的组合，同样可以使用交叉熵损失函数作为优化的目标函数。其中，$y_{ij}$和$\hat{y}_{ij}$分别为第$i$条评论文本的第$j$个标签的真实值和预测值，$y_{ij}\in{\{0,1\}}$，$\hat{y}_{ij}\in{[0,1]}$。
$$
\mathcal{L}=-\sum_{i=1}^{N}\sum_{j=1}^l[y_{ij}log\widehat{y}_{ij}+(1-y_{ij})log(1-\hat{y}_{ij})]
$$

## 4.2 模型改进

### 4.2.1 LSAN-CNN模型框架

LSAN模型在结构上具有两个创新之处：其一是提出了Label-Attenion机制，通过引入标签词向量充分利用了标签集所包含的语义信息，进而对标签集与文本之间的关联信息进行提取构造特征矩阵；其二是引入了Adaptive-Fusion机制，使得对基于Self-Attention和Label-Attention得到的两个特征矩阵进行加权时可以自动调整权重。得益于这两种机制的提出，LSAN模型在RCV1、AAPD、EUR-Lex和KanShan-Cup四个中英文大规模多标签文本分类数据集上取得了不错的分类效果。

在特征提取层，LSAN模型采用了Bi-LSTM网络。单向的LSTM网络可以按照语序从句首到句末提取语义信息，而双向的LSTM网络得到的特征则同时包含了前向和后向的语义信息，相比于单项的LSTM在特征提取上更为全面。但是，对于文本的局部语法特征（n-gram），LSTM网络并不能很好地捕捉。因此，本文提出LSAN-CNN模型，该模型在LSAN模型的特征提取阶段加入了textCNN作为局部语法特征提取器，旨在弥补LSAN模型在特征提取上存在的缺陷，提高模型整体的分类效果。

<img src="E:\研究生\毕业论文\Pictures\LSAN-CNN.jpg" alt="LSAN-CNN" style="zoom:50%;" />

### 4.2.2 LSAN-CNN模型原理

模型的输入部分仍然是预训练的文本词向量和标签集词向量，不同的是，除了经过Bi-LSTM层提取特征外，还需要同时经过textCNN层进行特征提取。记第$i$条文本的词向量矩阵为$x^{(i)}=\{w^{(i)}_1,w^{(i)}_2,\cdots,w^{(i)}_n\}$，其中$w^{(i)}_j$为第$j$个词的词向量，则$x^{(i)}$的维度为$(k,n)$。在textCNN中，卷积核的宽度与词向量的维度保持一致，而高度则自行确定，此处卷积核高度设为$(f_1,f_2,\cdots,f_s)$，而每种尺寸的卷积核数量设为$(N_1,N_2,\cdots,N_s)$，卷积步长设为1。记第$i$条文本对应的第$m$种卷积核尺寸下的卷积结果为$C^{(i)}_{m}$，$C^{(i)}_{mt}$为第$m$种卷积核第$t$次卷积计算的结果。经过多次卷积操作，得到多种不同维度的列向量，其中$C^{(i)}_{mt}$的维度为$(n-f_m,1)$。卷积操作之后，需要对每种卷积核得到的结果进行降维，本文采用的是最大池化（Max-Pooling）方法将每个每次卷积计算得到的列向量$C^{(i)}_{mt}$压缩为单个数值，最后将Max-Pooling得到的多个数值拼接为特征向量，维度为$(1,N_1+N_2+\cdots+N_s)$。
$$
C^{(i)}_{m}=Convolution(x^{(i)}) \\
C^{(i)}=MaxPooling(
\underbrace{C^{(i)}_{11},\cdots,C^{(i)}_{1N_1}}_{N_1},\ 
\underbrace{C^{(i)}_{21},\cdots,C^{(i)}_{2N_2}}_{N_2},\ 
\cdots\ \cdots,\ 
\underbrace{C^{(i)}_{s1},\cdots,C^{(i)}_{sN_s}}_{N_s}
)
$$
为使得LSAN模型中的特征向量和加入textCNN后得到的特征向量能够进行融合，在最后的全连接层也需要对LSAN模型进行改动，原LSAN模型将基于Self-Attention和Label-Attention得到的融合特征矩阵经过全连接层进行线性转换，而为了在维度上与textCNN得到的特征向量匹配，本文将全连接层改为平均池化（Average-Pooling）操作，对矩阵$M^{(i)}$进行降维操作，使其维度与$C^{(i)}$一致，因此需要对卷积核的数量作如下限制，其中$k$为词向量维度。
$$
\sum_{m=1}^s N_m=2k
$$
进而采用相加的方式对两个特征向量进行融合，最后再进入分类器层得到最终的预测结果。其中，$W_7$是$(2k,l)$维度的参数矩阵。
$$
\hat{y}_i=sigmoid([AvgPooling(M^{(i)})+C^{(i)}]W_7)
$$

## 4.3 基于LSAN-CNN模型的评论维度识别

将本文提出的LSAN-CNN模型应用于ASAP数据集的粗粒度评价维度识别任务中，模型的输入部分为上一章由Word2Vec预训练得到的词向量，由于词向量维度为768，输入词向量矩阵的维度为$(batch\_size,768,seq\_len)$，其中$batch\_size$和$seq\_len$分别为批数据的大小和评论文本序列长度，属于模型的超参数。标签部分，原数据集中的标签包含18个细粒度的评价维度，为了对粗粒度的评价维度进行识别，需要对原数据的标签进行处理，分离出粗粒度的评价维度。

### 4.3.1 ASAP数据集标签处理

ASAP数据集的细粒度评价维度命名方式遵循“粗粒度维度#细粒度维度”格式，例如“Location#Transportation”，其中位置（Location）为粗粒度维度，而交通是否便利（Transportation）为细粒度维度。为了使得数据能够适应粗粒度评价维度识别任务，对数据集作如下处理：当至少存在一个细粒度维度的情感极性不为“未提及”时，则对应的粗粒度维度赋予“提及”标签，具体样例如下所示。

<img src="E:\研究生\毕业论文\Pictures\LSAN-CNN标签处理.jpg" alt="LSAN-CNN标签处理" style="zoom:40%;" />

如图所示，以该条评论对应的标签为例，根据每一细粒度评价维度下的情感极性可以看出，“位置“维度均为提及，”服务“维度下提到了”服务态度“，”价格“维度下提到了”价格水平“和”折扣力度“，”环境“维度下提到了”装饰“、”噪声“、“空间”和”卫生程度”，而“菜品”维度下则提到了“外观”，因此在粗粒度维度层面下，除“位置”维度外，其余维度均提及。

对ASAP数据集的粗粒度评价维度作简单的统计分析可得到图，由图可知评论文本中提及最多的粗粒度维度为菜品（Food），其次为服务态度（Service）和价格水平（Price）。

<img src="E:\研究生\毕业论文\Pictures\label_stat.jpg" alt="label_stat" style="zoom:20%;" />

经过上述标签集处理后可以发现，针对ASAP数据集的粗粒度评价维度识别任务本质上属于多标签文本分类任务，标签数量为5个，分别为“价格”、“位置”、“环境”、“服务”和“菜品”。对应到LSAN-CNN模型中，输入的标签词向量矩阵$C$维度为$(batch\_size,768,5)$。

### 4.3.2 模型参数设置

模型的输入部分确定后，还需要初步确定超参数的值。在LSAN-CNN模型中，本文对超参数参考原LSAN模型作如下设置：①评论文本的最大长度设置为300；②特征提取层中Bi-LSTM网络的隐藏层维度$d_h$与词向量的维度保持一致，为768；③Self-Attention部分系数$W_1$和$W_2$的维度$d_a$为512；④对于textCNN特征提取部分，需要确定的有两部分，一是卷积核的尺寸$f_m$，二是每个尺寸卷积核的数量$N_m$。本文将采用四种尺寸的卷积核，高度分别为2、3、4、5，每种卷积核的数量保持一致，根据式的限制，可以推算出每种卷积核的数量为384个，因此$f_m=\{2,3,4,5\}$，而$N_m=384$。

模型训练方面，需要确定的超参数如下：①批数据的大小batch_size，该参数的选取与训练所使用的机器性能有关，batch_size越大训练时占用的内存就越多，对机器的性能要求就越高；而batch_size越小则所需要的训练时间就越长。经过测试，本文将batch_size设为128；②初始学习率大小learning_rate和衰减率decay_rate。模型训练过程中，学习率能够指导模型通过损失函数的梯度调整网络的权重，较小的学习率可以保证参数在更新过程中不会错过局部最优点，但损失函数收敛所耗费的时间也会更长；而较大的学习率会使损失函数难以收敛甚至发散。因此学习率的选取需要同时兼顾训练的时间成本和损失函数的收敛效果，当前大多数研究人员都会在模型训练中加入学习率衰减策略。本文选取线性衰减策略作为学习率的调整方案，即在训练过程中，学习率从初始学习率开始每隔一段时间按照衰减率线性下降。如此设置的好处是，初始训练阶段损失函数能够在较大学习率下快速向最优点靠近，而训练后期又能在较小学习率下缓慢寻找全局最优点。本文将初始学习率learning_rate设置为0.001，线性衰减率decay_rate设置为0.7；③迭代次数epochs，该参数决定模型遍历全部样本进行参数迭代更新的次数，epochs越大，则模型训练所花费的时间就越长，导致过拟合的可能性也越大，而epochs越小则模型可能无法收敛。因此，本文对不同epochs下模型的收敛情况作了对比后，确定模型的迭代次数为7次。

<img src="E:\研究生\毕业论文\Pictures\epoch_loss.jpg" alt="epoch_loss" style="zoom:25%;" />

| Parameter                  | Value        |
| -------------------------- | ------------ |
| max_seq_len                | 300          |
| $d_h$                      | 768          |
| $d_a$                      | 512          |
| $f_m$                      | {2, 3, 4, 5} |
| $N_m$                      | 384          |
| batch_size                 | 128          |
| learning_rate / decay_rate | 0.001 / 0.7  |
| epochs                     | 7            |

## 4.4 评价指标与结果分析

### 4.4.1 模型评价指标

为了体现本文所提出的LSAN-CNN模型的分类效果，并探究本文所提出模型相较于原模型在分类效果上是否有所提升，需要指定统一的评价指标。对于分类模型，最直观的评价指标为准确率（Accuracy），即完全分类正确的样本数占总样本数的比例。在多分类任务中该评价指标尚且合理，而在多标签分类任务中，由于一个样本可能包含多个标签类别，使用准确率作为评价指标虽然能从整体上反应模型的分类效果，但忽略了模型在单个类别上的分类准确率。

为了更全面地评价模型的分类效果，本文将对每个标签类别计算单独计算评价指标，而后对所有类别的评价指标取平均作为最终的指标计算结果。具体地，本文将采用宏平均精确率（Macro-Precision）、宏平均召回率（Macro-Recall）和宏平均F1（Macro-F1）作为模型分类效果的综合评价指标。

首先，针对单个类别可以得到如下所示的混淆矩阵，其中$a$为模型正确预测属于该类别的样本数，$b$为模型无法识别出该类别的样本数，$c$为模型误将不属于该类别的样本划分到该类别的样本数，$d$为模型正确预测不属于该类别的样本数。由此可以计算出精确率（Precision）、召回率（Recall）和F1（F1-Score）三个指标，精确率用于反映模型预测为正例的样本中其真实标签类别也为正的样本比例，召回率用于反映真是标签为正的样本中被模型准确识别的样本比例，而F1则是精确率和召回率的调和平均数，综合反映模型在该类别上的分类效果。

<img src="E:\研究生\毕业论文\Pictures\comfusion_matrix.png" alt="comfusion_matrix" style="zoom:60%;" />
$$
Precision=\frac{a}{a+c} \\
Recall=\frac{a}{a+b} \\
F1=\frac{2\times Precision\times Recall}{Precision+Recall}
$$
进而，可利用单个类别的精确率、召回率和F1计算宏平均指标，定义为：
$$
Macro-Precision=\frac{1}{n}\sum_{i=1}^n Precision_i \\
Macro-Recall=\frac{1}{n}\sum_{i=1}^n Recall_i \\
Macro-F1=\frac{1}{n}\sum_{i=1}^n F1_i
$$
其中，$n$为标签类别总数，本文研究中$n=5$。

### 4.4.2 模型训练结果

由于本地设备性能有限，本文研究所涉及模型训练部分均在谷歌的Colab云计算平台运行，硬件方面Colab平台提供了英伟达的Tesla T4系列GPU，拥有16GB显存，在上述参数条件下，单个epoch耗时6分钟左右，7个epoch训练总计耗时约42分钟。损失函数在训练集和验证集上的变化趋势如图所示。

<img src="E:\研究生\毕业论文\Pictures\lsancnn_loss.jpg" alt="lsancnn_loss" style="zoom:25%;" />

根据模型的预测结果计算各评价指标的值得到表，由表可知，无论是对于训练集、验证集还是测试集，三个指标中模型的宏精确率均比宏召回率稍高，在测试集上取得了93.58%的宏精确率和91.87%的宏召回率，而宏F1为92.70%。一般而言，模型的精确率和召回率变化会呈反向，提高精确率会使得召回率降低，而提高召回率又会使得损失精确率，因此需要在两个指标之间进行一定的取舍。本文所采用的模型在9个epoch的训练后精确率比召回率稍高，表面模型偏向于对标签预测的准确性，而可能对部分标签的识别存在遗漏，即对标签宁可漏判也不误判。该结果也符合本文研究的预期，若存在对标签的误判，则会向后续模型传递冗余信息，直接影响下游基于粗粒度评价维度融合的情感极性分类任务的效果。

|                     | Train  | Dev    | Test   |
| ------------------- | ------ | ------ | ------ |
| **Macro-Precision** | 0.9581 | 0.9365 | 0.9358 |
| **Macro-Recall**    | 0.9502 | 0.9189 | 0.9187 |
| **Macro-F1**        | 0.9536 | 0.9270 | 0.9270 |

具体地，对比单个类别下评价指标的值可以发现，无论是精确率、召回率还是F1-Score，“菜品”（Food）类别的评价指标值最高，而“位置”（Location）类别最低，表面模型在“菜品”这一粗粒度评价维度的识别效果最好，而对“位置”维度的识别效果较差。而总体上看，除“位置”外，各评价维度的指标值都在90%以上，表面模型在各个粗粒度评价维度的识别方面表现较好。

<img src="E:\研究生\毕业论文\Pictures\lsancnn_result_pic.jpg" alt="lsancnn_result_pic" style="zoom:25%;" />

LSAN-CNN模型在测试集的预测实例如图所示。第一、二个实例中模型对评论文本所包含的粗粒度评价维度作出了准确识别；第三个实例中，模型只识别出了“服务”和“菜品”维度，无法识别到“价格”维度，主要是因为评论中的“价格”主要体现在对性价比的描述上，语义表达相对比较隐晦，模型无法准确识别；而第四个实例中模型识别到评论文本涉及“服务”维度，而事实上并未提及，模型在该评论文本上出现了误判。

<img src="E:\研究生\毕业论文\Pictures\MLC_result.jpg" alt="MLC_result" style="zoom:100%;" />

### 4.4.3 模型对比分析

为验证本文所提出的LSAN-CNN模型的有效性，将LSAN-CNN的结果与LSAN模型进行比较。具体地，利用原LSAN模型早ASAP数据集上进行训练，参数设置与LSAN-CNN模型的训练过程保持一致，经过9个epoch的训练后对ASAP测试集的粗粒度评价维度进行预测，得到表所示的结果。由表可知，相比LSAN模型，LSAN-CNN模型在ASAP数据集的粗粒度评价维度识别任务上表现更佳，模型的宏精确率、宏召回率和宏F1分别较LSAN模型提升了1.92%、0.87%和1.47%。而从各个维度的评价指标上看，在“价格”、“位置”和“环境”维度的识别中，LSAN-CNN模型无论是在精确率、召回率还是F1上均优于LSAN模型；在“服务”维度的识别中，LSAN-CNN模型的召回率相较于LSAN模型要低，也导致了模型的F1较低，表明LSAN-CNN在该维度的识别上与LSAN模型相比存在一定程度的漏判；在“菜品”维度的识别中，LSAN-CNN模型的精确率低于LSAN模型，表明模型在该维度的识别上与LSAN模型相比存在一定程度的误判。

<img src="E:\研究生\毕业论文\Pictures\LSAN-CNN_compare.jpg" alt="LSAN-CNN_compare" style="zoom:50%;" />

<img src="E:\研究生\毕业论文\Pictures\metrics_compare_lsan.jpg" alt="metrics_compare_lsan" style="zoom:50%;" />

## 4.5 小结

本章介绍了在多标签文本分类领域应用效果较好的LSAN模型的基本原理，在此基础上对模型存在的不足加以改进，在特征提取层引入textCNN捕捉文本的n-gram特征，提出了LSAN-CNN模型。利用该模型对ASAP数据集的“价格”、“位置”、“服务”、“环境”和“菜品”五个粗粒度评价维度进行识别，并使用宏精确率、宏召回率和宏F1作为衡量模型分类效果的评价指标。经过7个epoch的训练，LSAN-CNN模型在ASAP测试集上取得93.58%的宏精确率、91.87%的宏召回率和92.70%的宏F1，相较于LSAN模型分别提升1.92%、0.87%和1.47%，表明textCNN模块的引入能够更全面地捕捉文本的语义特征，LSAN-CNN模型相比LSAN模型在多标签文本分类任务上具有更好的效果。
