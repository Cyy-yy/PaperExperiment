# 5. 基于ERNIE的方面级情感极性分类

ASAP数据集共包含18个细粒度评价维度，例如“位置“这一粗粒度维度下又包含”交通是否便利“、”距离商圈远近“和”是否容易寻找“三个细粒度维度，每个细粒度维度下又包含消极、中性、积极和未提及四类情感极性，而本文研究的最终目的是对单条评论文本的每一个细粒度评价维度进行情感极性分类。该任务本质上属于方面级情感分析任务，当前该领域主流的研究方法都是基于预训练模型，利用预训练过程中模型在大规模语料上习得的通用知识，辅以下游任务数据进行微调，便能够取得不错的分类效果。本文研究所采用的情感极性分类模型是百度的ERNIE预训练模型，在该模型基础上提出基于字词相似度加权的词向量构建方法，并将上一步中识别到的粗粒度评价维度的词向量与评论文本的词向量基于Attention机制进行交互，进而与评论文本的语义特征进行融合，完成基于ERNIE的细粒度评价维度情感极性分类任务。

本章首先对ERNIE预训练模型的基本原理作详细阐述，并提出基于字词相似度加权的词向量构建方法，将ERNIE模型产生的字向量转换为词向量。其次，为了捕捉评价维度于粗粒度评价维度的关联信息，本章还提出了基于Attention机制构造评价维度词向量的方法。进而将评价维度和评论文本的语义特征进行融合，并对比模型改进前后的分类效果，验证本文所提出方法的有效性。

## 5.1 ERNIE预训练模型分析

### 5.1.1 预训练模型概述

人类通过不断学习积累更丰富的知识，与人类的认知过程类似，要使得模型在各种任务上取得更好的效果就需要在规模足够大的数据集上进行训练。而数据规模越大，模型训练的时间成本和对硬件资源的要求就会越高。而预训练模型在预训练阶段通常会采用规模尽可能大的数据集，学习通用领域的知识，得到预训练的模型参数，而后只需要根据需求在特定领域数据集上对参数进行微调便可在下游相关任务上取得不错的效果，极大程度上降低了模型训练的时间成本和硬件开销，提高了模型开发的效率。

### 5.1.2 ERNIE预训练模型

2018年，Google的Devlin等提出了BERT模型，该模型采用堆叠的多层双向Transformer架构作为编码器，并在大规模语料上进行预训练，在文本分类、智能问答、文本推断等11个自然语言处理任务中实现SOTA效果。

<img src="E:\研究生\毕业论文\Pictures\BERT_Architecture.jpg" alt="BERT_Architecture" style="zoom:50%;" />

BERT的预训练任务为MLM（Masked Language Model）和NSP（Next Sentence Prediction）任务，在MLM任务中，模型随机输入语句的15%个单词作Mask操作，策略如下：①以80%的概率将单词替换为“[MASK]”标识符；②以10%的概率替换为随机选取的单词；③以10%的概率保持不变。该Mask策略相对简单，并没有充分利用到输入文本中蕴含的先验信息，因此百度的Sun等人在2019年提出了ERNIE（Enhanced Representation through Knowledge Integration）模型。ERNIE在BERT的基础上进行改进，模型主体结构不变，Base版本的模型依然由12个Transformer编码器构成，但在MLM预训练任务的Mask策略上作了优化，提出了三个层次的Mask策略，分别为原有的随机Mask策略、实体层面（Entity-level）的Mask策略和短语层面（Phrase-level）的Mask策略。其中，实体层面的Mask主要是对输入文本中提及的人物、地点、机构等实体作随机Mask操作，而短语层面的Mask则对文本中包含的固定短语作随机Mask操作。相较于BERT，ERNIE的Mask策略能够在MLM预训练任务中更完整地捕捉到文本中蕴含的实体和短语相关的先验知识，进而将这些信息整合到单词的语义表示中，使得模型最终得到的词向量包含更丰富的语义信息。

<img src="E:\研究生\毕业论文\Pictures\BERT_Mask.jpg" alt="BERT_Mask" style="zoom:80%;" />

<img src="E:\研究生\毕业论文\Pictures\ERNIE_Mask.jpg" alt="ERNIE_Mask" style="zoom:70%;" />

此外，作为国内最大的中文搜索引擎，百度在中文文本数据资源上具有天然优势。 在ERNIE的预训练阶段相比BERT新增了多个异质性的中文语料，包含中文维基百科、百度百科、百度新闻和百度贴吧等在内的多个中文语料数据集，总规模约为1.73亿条。得益于此，ERNIE能够在预训练阶段从大规模中文语料中学到更多的中文语义信息，也使得ERNIE能够应用于中文NLP任务中。

<img src="E:\研究生\毕业论文\Pictures\ERNIE_pretrained_corpus.jpg" alt="ERNIE_pretrained_corpus" style="zoom:50%;" />

## 5.2 基于字词相似度加权的词向量构建方法

### 5.2.1 构建方法概述

ERNIE在预训练阶段从大规模语料上学到的通用知识为模型的参数更新提供了一个很好的基础，只需要在特定任务的语料数据集上加以微调便能取得很好的效果，这种”大规模预训练+微调“的范式提高了模型的通用性，使得模型能够更好地适应下游不同任务。但是，当前大多数预训练模型包括ERNIE在内，其训练得到的语义表示均表现为字向量，即模型对输入的文本作了单字粒度上的切分，得到每一个字对应的语义表示。对于英文版本的预训练模型，其得到的是单词的词向量，而一个单词翻译为中文一般为词语，因此本质上模型学到的是词语的语义信息。但是，中文版本的模型得到的是单个汉字的字向量，对于对于中文而言，词语所表达的语义信息往往要比单个汉字更加丰富。基于这一前提，本文提出了一种基于字词相似度加权的词向量构建方法。

直观上看，将预训练模型得到的字向量转换为词向量的一种简单的处理方式是直接对字向量进行加总，该方法本质上是对每个字向量赋予了相同的权重，而事实上词语和其对应的字之间的相关性并非完全相同。以词语”三文鱼“其对应构成的汉字为例，记$\rho(a,b)$为$a$和$b$之间的相关系数，显然有$\rho(三文鱼,\ 鱼)\gt \rho(三文鱼,\ 三)\ or\ \rho(三文鱼,\ 鱼)\gt \rho(三文鱼,\ 文)$，因为”三文鱼“属于鱼类，理论上其语义信息与”鱼“字的语义信息最相似。因此简单地对字向量加总为词向量的做法忽略了这种先验信息，得到的词向量并不准确。基于字词相似度加权构建词向量能够考虑到字和词之间的语义相关性，充分捕捉字词之间的关联信息，在词向量的构造方法上比直接加总的方法更合理。

### 5.2.2 字词相似度计算

记词语的词向量为$w$，假定该词语由$m$个汉字构成，则$w$对应的字向量为$\{c_1,c_2,\cdots,c_m\}$。本文采用词向量与字向量的softmax归一化向量内积衡量词语与单个汉字之间的关联性，记为$W$，具体计算如式，其中词向量$w$和字向量$c_i$均为$k$维的列向量，因此该向量构建方法需要满足词向量与字向量的维度保持一致这一条件。
$$
W=softmax(w^T[c_1,c_2,\cdots,c_m])
$$
### 5.2.3 加权构建词向量

无论是预训练模型还是词向量模型，其输入部分都需要将文本对齐到同一长度，即需要为模型指定一个代表文本最大长度的超参数。由于对文本的切分粒度不同，同一个文本包含的字符数必然大于或等于其所包含的词语数，因此预训练模型和词向量模型对最大文本长度的设置也就会存在差异。正因如此，本文所提出的基于字词相似度加权的词向量构建方法在实际计算过程中将会面临以下两种情况：

①词语对应的字在预训练模型中被截断，导致无法匹配或无法完整匹配到对应的字向量。对于这一种情况，本文研究的处理方法是不对字向量作加权，直接取用词向量模型生成的词向量，在后续模型训练中作调整。

②分词后对于单字成词的情况，本文采用的处理方式是取其对应的字向量代替加权词向量进行后续计算。

以图中评论文本为例，该评论文本包含12个字符，经由预训练模型将产生12个字向量$\{c_1,c_2,\cdots,c_{12}\}$。若采用python的jieba分词工具，可将其分为7个词语，经由词向量模型将产生7个词向量$\{w_1,w_2,\cdots,w_7\}$。其中，$c_i$和$w_i$为$k$维列向量。具体计算方法如下：

<img src="E:\研究生\毕业论文\Pictures\weighted_embedding.jpg" alt="weighted_embedding" style="zoom:50%;" />
$$
W_1=softmax(w_1^T[c_1,c_2]) \qquad w_1^\prime=[c_1,c_2]W_1^T \\
W_2=softmax(w_2^T[c_3,c_4]) \qquad w_2^\prime=[c_3,c_4]W_2^T \\
W_5=softmax(w_5^T[c_7,c_8,c_9]) \qquad w_5^\prime=[c_7,c_8,c_9]W_5^T \\
W_7=softmax(w_7^T[c_{11},c_{12}]) \qquad w_7^\prime=[c_{11},c_{12}]W_7^T \\
$$
<img src="E:\研究生\毕业论文\Pictures\weighted_embedding_2.jpg" alt="weighted_embedding_2" style="zoom:50%;" />

可以看到，基于字词相似度加权的词向量构造方法将原有的词向量$w_i$转换为加权的词向量$w_i^\prime$，其中$w_3$、$w_4$和$w_6$对应的词语属于单子成词，因此使用其对应的字向量$c_5$、$c_6$和$c_{10}$进行后续计算。

## 5.3 基于Attention机制的评价维度词向量

### 5.3.1 方法概述

人工对评论文本进行细粒度维度层面的情感分析时，一般可以先判断评论文本所提及的粗粒度维度，再根据评论文本中与粗粒度维度相关的语句的上下文作判断，进一步得到细粒度维度下的情感极性。基于这一思路，为了提取评论文本和粗粒度评价维度之间的关联信息，本文研究提出了基于Attention机制构造评价维度词向量的方法。

上一章中，基于LSAN-CNN模型可以预测评论文本所提及的粗粒度评价维度，本节将利用Attention机制，将该粗粒度评价维度的语义信息与评论文本的语义信息进行交互，得到基于Attention机制的评价维度词向量，用于下游计算。记单条评论文本的词向量构成的矩阵为$R$，维度为$(k,n)$；记粗粒度评价维度的词向量矩阵为$D$，维度为$(k,5)$。其中，$k$为词向量维度。而评价维度矩阵$D$的维度为$(d,5)$主要是由于ASAP数据集包含5个粗粒度评价维度，在评价维度识别任务中，单个评论文本可能涉及一个或多个评价维度，因此在构造评价维度矩阵时需要对维度作补齐操作，不足5个粗粒度评价维度的样本将使用“[PAD]”标识符作补充。由于“[PAD]”标识符并没有特殊的语义信息，对其作Attention操作也没有意义，因此本文研究在计算过程中加入了Attention-Mask操作，即采用一个0-1向量表示是否对词语作Attention操作，0表示忽略该位置对应词语的Attention操作。具体Attention操作计算如下：
$$
U=tanh(W_aR+b_a) \\
\alpha=softmax(U^TD) \\
D^\prime=R\alpha
$$
其中，$W_a$和$b_a$为模型参数，维度为$(k,k)$。

### 5.3.2 计算流程

完整的计算流程如下所示，首先将预测得到的粗粒度评价维度转换为词向量$D$并作padding操作，同时根据padding的情况得到Attention Mask向量，进而利用Attention机制提取评论文本和评价维度之间的管联信息，得到基于Attention机制的评价维度词向量$D^\prime$，最后根据Attention Mask向量对“[PAD]”标识符的Attention操作作掩盖，得到最终的评价维度词向量$D^{\prime\prime}$。

<img src="E:\研究生\毕业论文\Pictures\AttentionDimensionWord.jpg" alt="AttentionDimensionWord" style="zoom:50%;" />

## 5.4 模型训练

### 5.4.1 情感极性分类模型框架

在对基于字词相似度加权的词向量构建方法和基于Attention机制的评论维度词向量的计算方法作详细介绍后，本文研究将对这两种方法所产生的词向量作融合，进一步地提取语义特征，完成细粒度评价维度的情感极性分类任务。完整的任务框架如图所示，整个任务流程可以分为三大部分：①利用ERNIE预训练模型产生的字向量和Word2Vec产生的词向量，基于字词相似度对字向量加权构造新的词向量；②利用注意力机制对第四章中预测得到的粗粒度评价维度的词向量和评论文本的词向量作交互，提取两者之间的关联信息，得到基于注意力机制的粗粒度评价维度词向量；③将基于字词相似度加权构建的评论文本词向量和基于注意力机制的粗粒度评价维度词向量作拼接，将维度信息融合到评论文本中，并采用Bi-LSTM网络进一步提取语义特征，然后经过池化层降维，最后再输入分类器中得到不同细粒度评价维度下的情感极性。

<img src="E:\研究生\毕业论文\Pictures\Aspect_SA_framework.jpg" alt="Aspect_SA_framework" style="zoom:50%;" />

### 5.4.2 模型损失函数

模型最终将预测不同18个细粒度评价维度下的情感极性，而情感极性又包含未提及、消极、中性和积极4类，因此对单条评论文本的输出结果将是一个$(18,4)$维度的矩阵，每一行代表该维度下各种情感极性的概率。从本质上看，在Softmax分类层模型同时作了18次4分类，因此在细粒度评价维度情感极性分类任务上模型的损失函数可以采用交叉熵损失函数。
$$
\mathcal L=-\sum_{i=1}^{N}\sum_{j=1}^{18}\sum_{k=1}^{4}y_{jk}^{(i)}log\widehat{y_{jk}^{(i)}}
$$
### 5.4.3 模型参数设置

模型参数方面，主要有以下几个超参数需要设定：①词向量的维度k，由于该部分所采用的词向量来自上一个任务中经过Word2Vec模型预训练的词向量，且后续语义信息的融合采用的方式是作横向的拼接，词向量的维度应保持一致，为768；②最大文本长度max_seq_len，由于对文本的切分粒度不同，该参数在ERNIE模型和Word2Vec模型中的设置会存在一定的差异，本文将ERNIE模型中的最大文本长度保持默认的512不变，而对Word2Vec模型则仍然采用300；③Top-k池化的比例pool_prop，该参数决定对特征向量的压缩程度，当特征向量为n维时，经过Top-k池化后将返回前(n×pool_prop)个最大的元素。该比例过大，则起不到特征降维减小计算量的效果，而比例过小，又会损失过多特征向量的信息，因此本文研究将pool_prop参数设置为0.5。

模型训练方面，相关的参数设置如下：①学习率learning_rate，本文采用Adam优化器，结合学习率线性衰减策略对模型作梯度更新。在优化器中指定learning_rate为0.0005，线性衰减策略中指定预热比率warmup_rate为0.2。设模型总迭代次数为num_training_steps，则在该线性衰减策略下学习率将先从0开始经过(num_training_steps×0.2)步线性增加至0.0005，随后开始线性下降至0。使用该策略的好处在于，在模型训练初期能够以较小的学习率保证训练的稳定性，而后期又能以较大的学习率加快损失函数收敛的速度；②批数据大小batch_size，由于使用了ERNIE预训练模型，参数量达到了110M，batch_size设置为较小的16，防止训练过程中内存溢出；③迭代次数epochs，根据损失函数的变化，将迭代次数设置为。

| **Parameter** | **Value**                      |
| ------------- | ------------------------------ |
| k             | 768                            |
| max_seq_len   | 512（ERINIE）/ 300（Word2Vec） |
| pool_prop     | 0.5                            |
| learning_rate | 0.0005                         |
| warmup_rate   | 0.2                            |
| batch_size    | 16                             |
| epochs        |                                |

### 5.4.4 模型输入数据结构

模型输入方面，针对基于字词相似度加权构建词向量模块，为了使得词向量能够与对应的字向量作相似度计算，需要对该模块输入数据作一定的处理。本文研究将输入数据构造为如下形式，针对每条评论文本构造索引矩阵，矩阵维度为n行3列，n为文本长度。索引矩阵的每一行包含三个元素，第一个元素为词语在词典中的索引，后两个元素为词语对应的字在评论文本中的起始位置和终止位置索引。

<img src="E:\研究生\毕业论文\Pictures\weighted_embedding_input.jpg" alt="weighted_embedding_input" style="zoom:35%;" />

由于ERNIE预训练模型包含12个Transformer编码器，结构较为庞大，参数量较多，若将所有编码器层进行参数更新，则对内存的要求比较高。本文研究虽借助Google的Colab云计算平台进行模型训练，但内存资源仍然有限，因此本文研究将对ERNIE预训练模型的前11个Transformer编码器的参数进行冻结，训练过程只更新最后一个编码器以及后续层的参数，提高训练效率。

## 5.5 模型结果分析

### 5.5.1 模型评价指标

由于ASAP数据集的标签共包含18个细粒度评价维度，而每个评价维度下又包含4种情感极性，对评论文本细粒度评价维度的情感极性分类本质上是同时进行18个4分类任务。因此，模型可以采用与粗粒度评价维度识别任务一致的评价指标，即先计算每个细粒度评价维度的宏评价指标，再对所有评价维度的宏评价指标取平均作为最终衡量模型情感极性分类效果的指标。
$$
Macro-Pecision=\sum_{i=1}^{18}P^{(i)}_{macro} \\
Macro-Recall=\sum_{i=1}^{18}R^{(i)}_{macro} \\
Macro-F1=\sum_{i=1}^{18}F1^{(i)}_{macro} \\
$$
### 5.5.2 模型训练结果

由于ERNIE预训练模型参数规模较大，本地设备性能有限，模型训练仍在Google的Colab云计算平台上进行。在单块Nvidia Tesla T4显卡条件下，模型训练单个epoch耗时约2小时，20个epoch总训练耗时约为40个小时。训练过程中，模型损失函数的变化过程如图所示，经过20个epoch的迭代，损失函数趋于平稳。训练结束后，将所得模型在测试集语料上做预测，并计算预测结果的宏精确率、宏召回率和宏F1，得到如下结果。

| Metrics         | Value  |
| --------------- | ------ |
| Macro-Precision | 0.6975 |
| Macro-Recall    | 0.7003 |
| Macro-F1        | 0.6989 |

在细粒度评价维度的情感极性分类任务中，模型在测试集上的宏精确率为0.6975，宏召回率为0.7003，宏F1为0.6989。从指标值上看，模型的分类效果并没有很好，究其原因，本文总结为以下两个方面：①模型所要完成的任务是需要同时判断18个细粒度评价维度下的情感极性，而每个评价维度下的情感极性又有4种可能，相比于简单的二分类或多分类，同时处理18个4分类任务对模型的挑战更大。因此，要想在评价指标上取得0.9以上的表现是比较困难的；②该任务中将上一阶段预测所得粗粒度评价维度信息与评论文本作了Attention交互，并作了特征融合，因此上一阶段粗粒度评价维度识别任务的识别效果会直接影响下游情感极性分类的结果，换言之，误差的传导会在一定程度上影响到该任务模型的分类表现。但总体上看，将基于字词相似度加权的词向量构建方法引入到ERNIE预训练模型中，在ASAP数据集的情感极性分类上取得的评价指标值都在0.65以上，而宏召回率则突破了0.7，模型分类效果在可接受范围内。

具体地，使用该模型对测试集评论文本的预测实例如下所示。

<img src="E:\研究生\毕业论文\Pictures\Aspect_SA_example.jpg" alt="Aspect_SA_example" style="zoom: 67%;" />

### 5.5.3 消融实验

为进一步探究本文所提出的基于字词相似度加权的词向量构建方法和基于Attention机制的评价维度词向量在模型中的有效性，本文还设计了如下消融实验：①删除模型架构中的字词相似度加权构建词向量的模块（w/o  weighted embedding），直接采用预训练模型生成的字向量与基于Attention机制的评价维度融合进行后续计算，该实验主要验证字词相似度加权构建词向量模块的有效性；②删除基于Attention机制构建评价维度词向量模块（w/o dimension embedding），直接将加权构建的词向量输入后续网络层进行计算，该实验主要研究基于Attention机制的评价维度词向量对模型分类效果的影响。

保持模型其余参数设置不变，同样基于Colab平台进行模型训练，得到实验结果如下：

<img src="E:\研究生\毕业论文\Pictures\Aspect_SA_ablation.jpg" alt="Aspect_SA_ablation" style="zoom:50%;" />

<img src="E:\研究生\毕业论文\Pictures\ablation_result.jpg" alt="ablation_result" style="zoom:20%;" />

由消融实验结果可以得出以下结论：①与删除字词相似度加权构建词向量模块的方法相比，本文所采用的模型在宏精确率、宏召回率和宏F1上分别提升2.77%、2.88%和2.82%，表明基于字词相似度加权构建词向量与直接采用ERNIE预训练模型的字向量建模相比，能够包含更丰富的语义信息，在ASAP数据集上能够取得更好的情感极性分类效果；②与删除基于Attention机制构建评价维度词向量模块的模型相比，本文所采用的模型在宏精确率、宏召回率和宏F1上分别提升1.95%、1.2%和1.58%，表明基于Attention机制构造评价维度词向量能够很好地捕捉评价维度与评论文本之间的关联信息，对评价维度与评论文本的语义信息融合能够进一步提升模型的情感极性分类表现。

## 5.6 小结

本章介绍了ERNIE预训练模型的基本原理，针对中文领域预训练模型采用字向量建模存在的不足，提出了基于字词相似度加权的词向量构建方法。在此基础上，为捕捉粗粒度评价维度与评论文本之间的关联语义信息，本文提出了基于Attention机制构建评价维度词向量的方法，对评价维度和评论文本的词向量作Attention交互。最终将基于字词相似度加权的评论文本词向量和基于Attention机制的粗粒度评价维度词向量融合，输入后续特征提取器和分类器中，得到不同细粒度评价维度下的情感极性。实验结果显示，本文所提出的模型改进方法在细粒度评价维度情感极性分类任务中的宏精确率为0.6975，宏召回率为0.7003，宏F1为0.6989。为进一步探究所提出的改进方法的有效性，本文还做了对应的消融实验，结果显示，基于字词相似度加权的词向量构建方法使得模型在宏精确率、宏召回率和宏F1上分别提升2.77%、2.88%和2.82%，而基于Attention机制构建评价维度词向量进而与评论文本做语义特征融合的策略使得模型在三个评价指标上分别提升1.95%、1.2%和1.58%。总体上看，消融实验结果表明本文所提出的基于字词相似度的词向量构建方法是有效的。